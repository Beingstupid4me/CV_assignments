{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEvHhpBV1x7W",
        "outputId": "0204d703-4b12-44d7-93a3-3df85cd6dacf"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m,force_remount\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Define the path to your dataset in Google Drive\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "# Define the path to your dataset in Google Drive\n",
        "data_dir = \"/content/drive/MyDrive/dataset/Cropped_final\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HctEPzV535N",
        "outputId": "55f2e0e0-f9f2-4b89-fc75-b239628fd747"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Images: 11668\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# Define class label mapping\n",
        "class_mapping = {\n",
        "    'amur_leopard': 0, 'amur_tiger': 1, 'birds': 2, 'black_bear': 3,\n",
        "    'brown_bear': 4, 'dog': 5, 'roe_deer': 6, 'sika_deer': 7,\n",
        "    'wild_boar': 8, 'people': 9\n",
        "}\n",
        "\n",
        "# Load image paths & labels\n",
        "image_paths, labels = [], []\n",
        "for class_name, class_label in class_mapping.items():\n",
        "    class_folder = os.path.join(data_dir, class_name)\n",
        "    if os.path.isdir(class_folder):\n",
        "        for img_file in os.listdir(class_folder):\n",
        "            if img_file.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
        "                image_paths.append(os.path.join(class_folder, img_file))\n",
        "                labels.append(class_label)\n",
        "\n",
        "# Convert to numpy arrays for stratified split\n",
        "image_paths, labels = np.array(image_paths), np.array(labels)\n",
        "print(f\"Total Images: {len(image_paths)}\")\n",
        "\n",
        "# Perform Stratified Split (80% Train, 20% Validation)\n",
        "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
        "train_idx, val_idx = next(splitter.split(image_paths, labels))\n",
        "\n",
        "train_paths, train_labels = image_paths[train_idx], labels[train_idx]\n",
        "val_paths, val_labels = image_paths[val_idx], labels[val_idx]\n",
        "\n",
        "# Define Custom Dataset Class\n",
        "class WildlifeDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "# Define Transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "# Create Dataset Instances\n",
        "train_dataset = WildlifeDataset(train_paths, train_labels, transform=train_transform)\n",
        "val_dataset = WildlifeDataset(val_paths, val_labels, transform=val_transform)\n",
        "\n",
        "# Create Data Loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0LPhiZH566k",
        "outputId": "435c0dfd-0098-4c5e-ad4e-04f80461c006"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 173MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Modify last layer to classify 10 classes\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmIuFgys6QKT"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_acc = correct / total\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2TZXs3l6SnW"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Evaluate Model\n",
        "model.eval()\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = outputs.max(1)\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Compute Accuracy\n",
        "val_acc = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_mapping.keys(), yticklabels=class_mapping.keys())\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2CmUwLY6hq_"
      },
      "outputs": [],
      "source": [
        "# Extract Features for t-SNE\n",
        "feature_extractor = models.resnet18(pretrained=True)\n",
        "feature_extractor.fc = nn.Identity()\n",
        "feature_extractor = feature_extractor.to(device)\n",
        "feature_extractor.eval()\n",
        "\n",
        "features, labels_list = [], []\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        embeddings = feature_extractor(images)\n",
        "        features.extend(embeddings.cpu().numpy())\n",
        "        labels_list.extend(labels.cpu().numpy())\n",
        "\n",
        "features = np.array(features)\n",
        "labels_list = np.array(labels_list)\n",
        "\n",
        "# 2D t-SNE\n",
        "tsne_2d = TSNE(n_components=2, perplexity=30, random_state=42)\n",
        "features_2d = tsne_2d.fit_transform(features)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1], c=labels_list, cmap=\"jet\", alpha=0.6)\n",
        "plt.colorbar(scatter, ticks=range(10))\n",
        "plt.title(\"2D t-SNE Visualization of Features\")\n",
        "plt.show()\n",
        "\n",
        "# 3D t-SNE\n",
        "tsne_3d = TSNE(n_components=3, perplexity=30, random_state=42)\n",
        "features_3d = tsne_3d.fit_transform(features)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection=\"3d\")\n",
        "scatter = ax.scatter(features_3d[:, 0], features_3d[:, 1], features_3d[:, 2], c=labels_list, cmap=\"jet\", alpha=0.6)\n",
        "plt.colorbar(scatter, ticks=range(10))\n",
        "ax.set_title(\"3D t-SNE Visualization of Features\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
